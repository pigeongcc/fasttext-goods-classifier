{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2PvzV7LPsylG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pickle\n",
        "from pprint import pprint\n",
        "from typing import NamedTuple, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "import pyarrow.parquet as pq\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.metrics import f1_score\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import optuna\n",
        "from utils.DataProcessor import DataProcessor\n",
        "from utils.eda import eda\n",
        "from utils.Oversampler import Oversampler\n",
        "from utils.TargetEncodersWrapper import TargetEncodersWrapper\n",
        "from utils.TextProcessor import TextProcessor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SEED = 8\n",
        "LOG_INTERVAL = 11\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fec1f6d2770>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.manual_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owlObq_RsylL"
      },
      "source": [
        "# Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_processor = DataProcessor(embedding_model='cc.ru.300.bin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6FRizxDsylM"
      },
      "source": [
        "## Reading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxwITEzTsylN",
        "outputId": "96beb60d-2632-43a3-ff68-0de85fc138ad"
      },
      "outputs": [],
      "source": [
        "train_data = pq.read_table('./data/train.parquet').to_pandas().set_index('product_id')\n",
        "test_data = pq.read_table('./data/test.parquet').to_pandas().set_index('product_id')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "w6_qYshTsylN"
      },
      "source": [
        "## EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A4AQkaBisylO"
      },
      "source": [
        "Let's look at the dataframes and their sizes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "7C-H2lpIsylO",
        "outputId": "1e8eb0ba-a848-4090-8be9-46c64a1f83ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(91120, 7)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category_id</th>\n",
              "      <th>sale</th>\n",
              "      <th>shop_id</th>\n",
              "      <th>shop_title</th>\n",
              "      <th>rating</th>\n",
              "      <th>text_fields</th>\n",
              "      <th>category_name</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>325286</th>\n",
              "      <td>12171</td>\n",
              "      <td>False</td>\n",
              "      <td>9031</td>\n",
              "      <td>Aksik</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{\"title\": \"Зарядный кабель Borofone BX1 Lightn...</td>\n",
              "      <td>Все категории-&gt;Электроника-&gt;Смартфоны и телефо...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888134</th>\n",
              "      <td>14233</td>\n",
              "      <td>False</td>\n",
              "      <td>18305</td>\n",
              "      <td>Sela</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{\"title\": \"Трусы Sela\", \"description\": \"Трусы-...</td>\n",
              "      <td>Все категории-&gt;Одежда-&gt;Женская одежда-&gt;Белье и...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1267173</th>\n",
              "      <td>13429</td>\n",
              "      <td>False</td>\n",
              "      <td>16357</td>\n",
              "      <td>ЮНЛАНДИЯ канцтовары</td>\n",
              "      <td>5.0</td>\n",
              "      <td>{\"title\": \"Гуашь \\\"ЮНЫЙ ВОЛШЕБНИК\\\", 12 цветов...</td>\n",
              "      <td>Все категории-&gt;Хобби и творчество-&gt;Рисование-&gt;...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            category_id   sale  shop_id           shop_title  rating  \\\n",
              "product_id                                                             \n",
              "325286            12171  False     9031                Aksik     5.0   \n",
              "888134            14233  False    18305                 Sela     5.0   \n",
              "1267173           13429  False    16357  ЮНЛАНДИЯ канцтовары     5.0   \n",
              "\n",
              "                                                  text_fields  \\\n",
              "product_id                                                      \n",
              "325286      {\"title\": \"Зарядный кабель Borofone BX1 Lightn...   \n",
              "888134      {\"title\": \"Трусы Sela\", \"description\": \"Трусы-...   \n",
              "1267173     {\"title\": \"Гуашь \\\"ЮНЫЙ ВОЛШЕБНИК\\\", 12 цветов...   \n",
              "\n",
              "                                                category_name  \n",
              "product_id                                                     \n",
              "325286      Все категории->Электроника->Смартфоны и телефо...  \n",
              "888134      Все категории->Одежда->Женская одежда->Белье и...  \n",
              "1267173     Все категории->Хобби и творчество->Рисование->...  "
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(train_data.shape)\n",
        "train_data.iloc[0:3]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "kHTh7rilsylP",
        "outputId": "6d9aa87a-0084-4657-8b21-41efb15881c9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(16860, 5)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sale</th>\n",
              "      <th>shop_id</th>\n",
              "      <th>shop_title</th>\n",
              "      <th>rating</th>\n",
              "      <th>text_fields</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>product_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1997646</th>\n",
              "      <td>False</td>\n",
              "      <td>22758</td>\n",
              "      <td>Sky_Electronics</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>{\"title\": \"Светодиодная лента Smart led Strip ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927375</th>\n",
              "      <td>False</td>\n",
              "      <td>17729</td>\n",
              "      <td>Di-Di Market</td>\n",
              "      <td>4.405941</td>\n",
              "      <td>{\"title\": \"Стекло ПЛЕНКА керамик матовое Honor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1921513</th>\n",
              "      <td>False</td>\n",
              "      <td>54327</td>\n",
              "      <td>VisionStore</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>{\"title\": \"Проводные наушники с микрофоном jac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             sale  shop_id       shop_title    rating  \\\n",
              "product_id                                              \n",
              "1997646     False    22758  Sky_Electronics  5.000000   \n",
              "927375      False    17729     Di-Di Market  4.405941   \n",
              "1921513     False    54327      VisionStore  4.000000   \n",
              "\n",
              "                                                  text_fields  \n",
              "product_id                                                     \n",
              "1997646     {\"title\": \"Светодиодная лента Smart led Strip ...  \n",
              "927375      {\"title\": \"Стекло ПЛЕНКА керамик матовое Honor...  \n",
              "1921513     {\"title\": \"Проводные наушники с микрофоном jac...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(test_data.shape)\n",
        "test_data.iloc[0:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3WRcudSsylQ"
      },
      "source": [
        "Make sure the columns are in appropriate formats."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o_yJV3PDsylQ",
        "outputId": "9798882e-2ca6-4435-a431-f82789c397e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "category_id        int64\n",
            "sale                bool\n",
            "shop_id            int64\n",
            "shop_title        object\n",
            "rating           float64\n",
            "text_fields       object\n",
            "category_name     object\n",
            "dtype: object \n",
            "\n",
            "sale              bool\n",
            "shop_id          int64\n",
            "shop_title      object\n",
            "rating         float64\n",
            "text_fields     object\n",
            "dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(train_data.dtypes, '\\n')\n",
        "print(test_data.dtypes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KM1bs7MqsylR"
      },
      "source": [
        "Missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "P_lA3FEdsylS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values percentage:\n",
            "category_id      0.0\n",
            "sale             0.0\n",
            "shop_id          0.0\n",
            "shop_title       0.0\n",
            "rating           0.0\n",
            "text_fields      0.0\n",
            "category_name    0.0\n",
            "dtype: float64\n",
            "\n",
            "Unique values percentage:\n",
            "category_id       0.959175\n",
            "sale              0.002195\n",
            "shop_id          11.577041\n",
            "shop_title       11.577041\n",
            "rating            2.543898\n",
            "text_fields      99.518218\n",
            "category_name     0.959175\n",
            "dtype: float64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eda(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CzeiLoYPsylS"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Missing values percentage:\n",
            "sale           0.0\n",
            "shop_id        0.0\n",
            "shop_title     0.0\n",
            "rating         0.0\n",
            "text_fields    0.0\n",
            "dtype: float64\n",
            "\n",
            "Unique values percentage:\n",
            "sale            0.011862\n",
            "shop_id        31.049822\n",
            "shop_title     31.049822\n",
            "rating          5.041518\n",
            "text_fields    99.768683\n",
            "dtype: float64\n",
            "\n"
          ]
        }
      ],
      "source": [
        "eda(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkUavXpdsylS"
      },
      "source": [
        "Class balance in the train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ydN5IRW7sylT",
        "outputId": "4f35df8e-f825-445d-8933-981b5c933fc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of unique categories: 874\n",
            "11937    6590\n",
            "14922    3709\n",
            "13651    1463\n",
            "13143    1460\n",
            "12980    1222\n",
            "Name: category_id, dtype: int64\n",
            "12808    2\n",
            "12901    1\n",
            "11549    1\n",
            "11875    1\n",
            "12836    1\n",
            "Name: category_id, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(f'Number of unique categories: {train_data[\"category_id\"].nunique()}')\n",
        "train_class_balance = train_data['category_id'].value_counts()\n",
        "print(train_class_balance.iloc[:5])\n",
        "print(train_class_balance.iloc[-5:])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7N1GCeaBsylT",
        "outputId": "e9de5bb5-4eb1-41c0-84a9-ce9eaecb6de5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "count     874.000000\n",
              "mean      104.256293\n",
              "std       300.107191\n",
              "min         1.000000\n",
              "25%        14.000000\n",
              "50%        38.000000\n",
              "75%        99.000000\n",
              "max      6590.000000\n",
              "Name: category_id, dtype: float64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_class_balance.describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "IywNefctsylU"
      },
      "source": [
        "The classes are imbalanced. Let us oversample the rare classes. The simple approach is to replicate the rare classes samples."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Oversampling of Rare Classes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let us bring each class number of examples up to `lower_limit`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11937    6590\n",
              "14922    3709\n",
              "13651    1463\n",
              "13143    1460\n",
              "12980    1222\n",
              "         ... \n",
              "13346      50\n",
              "14585      50\n",
              "11636      50\n",
              "15042      50\n",
              "13376      50\n",
              "Name: category_id, Length: 874, dtype: int64"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "oversampler = Oversampler()\n",
        "train_data = oversampler.oversample(train_data, target='category_id', lower_limit=50, reset_index=True)\n",
        "train_data['category_id'].value_counts()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have conducted experiments on datasets with and without oversampling. The best architecture (described further at `NN` section) was trained with the same parameters.\n",
        "\n",
        "Resulted F1-Weighted scores:\n",
        "\n",
        "- without oversampling: `0.884`\n",
        "- with oversampling: `0.895`"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "e9KTGk8RsylU"
      },
      "source": [
        "## Dictionary category_id -> category_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-n6-KTmpsylU"
      },
      "source": [
        "I have built a mapping from `category_id` to `category_name` and saved it to file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "iQ0a0FkcsylV",
        "outputId": "d48c1bad-be2a-4ee6-eff4-7fc633bf1ec5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Все категории->Одежда->Женская одежда->Белье и купальники->Майки и топы бельевые'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "category_name_path = 'category_name.pickle'\n",
        "\n",
        "with open(category_name_path, 'rb') as f:\n",
        "    category_name = pickle.load(f)\n",
        "\n",
        "category_name[2601]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0PTlVHwsylV"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdXGze_ZsylW"
      },
      "source": [
        "### Unwrapping the text data dictionaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "YucqCC2gsylX"
      },
      "outputs": [],
      "source": [
        "train_data['title'], train_data['description'], train_data['attributes'], train_data['characteristics'] =\\\n",
        "    zip(*train_data['text_fields'].apply(data_processor.process_json))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Categorical Features Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Sale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2599    0.037037\n",
              "2601    0.038095\n",
              "2730    0.016000\n",
              "2744    0.008850\n",
              "2746    0.058824\n",
              "2748    0.006329\n",
              "2769    0.001618\n",
              "2803    0.010373\n",
              "2804    0.002288\n",
              "2824    0.022388\n",
              "Name: category_id, dtype: float64"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_class_balance = train_data['category_id'].value_counts()\n",
        "train_class_balance_sale = train_data[train_data['sale']]['category_id'].value_counts()\n",
        "(train_class_balance_sale / train_class_balance).dropna()[0:10]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `sale` feature seems to be useless. Let us drop it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Shop ID"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Shops, in contrast, could include some useful information. Many sellers have limited assortiment of goods, so knowing a seller could help predicting their goods category.\n",
        "\n",
        "I applied the multiclass target encoding for the `shop_id` (= `shop_title`) feature. However, it hasn't improved the target metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# shop_encoders_path = './shop_encoders.pickle'\n",
        "# shop_encoders_wrapper = TargetEncodersWrapper()\n",
        "# shop_encoders = shop_encoders_wrapper.load(encoders_path=shop_encoders_path)\n",
        "\n",
        "# if shop_encoders is None:\n",
        "#     df_shop_encodings = shop_encoders_wrapper.fit_transform(train_data, 'shop_title', 'category_id', shop_encoders_path)\n",
        "# else:\n",
        "#     df_shop_encodings = shop_encoders_wrapper.transform(train_data, 'shop_title', shop_encoders)\n",
        "    \n",
        "# train_data = pd.concat([train_data, df_shop_encodings], axis=1)\n",
        "# train_data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_df_with_processed_text_features(df: pd.DataFrame,\n",
        "                                        text_features: list,\n",
        "                                        processor: TextProcessor,\n",
        "                                        path: str):\n",
        "    \"\"\" Loads the dataframe from `path`.\n",
        "    If `path` is not found, saves the dataframe concatenated with\n",
        "    embedded `text_features` to `path`.\n",
        "    Returns: `df` with embeddings concatenated to the right of the table.\n",
        "    \"\"\"\n",
        "\n",
        "    if not os.path.exists(path):\n",
        "        for text_feature in text_features:\n",
        "            df[text_feature] = df[text_feature].apply(lambda x: processor.process(x))\n",
        "        df.to_csv(path)\n",
        "    else:\n",
        "        df = pd.read_csv(path, index_col=0).fillna('')\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_data_path = './train_data_preprocessed_final.csv'\n",
        "text_features = ['title', 'description', 'attributes', 'characteristics']\n",
        "train_data = get_df_with_processed_text_features\\\n",
        "    (train_data, text_features, data_processor.text_processor, train_data_path)\n",
        "\n",
        "train_data = train_data.drop(columns=['rating', 'sale', 'shop_id', 'shop_title', 'text_fields'])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Text Vectorization with FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title.0</th>\n",
              "      <th>title.1</th>\n",
              "      <th>title.2</th>\n",
              "      <th>title.3</th>\n",
              "      <th>title.4</th>\n",
              "      <th>title.5</th>\n",
              "      <th>title.6</th>\n",
              "      <th>title.7</th>\n",
              "      <th>title.8</th>\n",
              "      <th>title.9</th>\n",
              "      <th>...</th>\n",
              "      <th>characteristics.290</th>\n",
              "      <th>characteristics.291</th>\n",
              "      <th>characteristics.292</th>\n",
              "      <th>characteristics.293</th>\n",
              "      <th>characteristics.294</th>\n",
              "      <th>characteristics.295</th>\n",
              "      <th>characteristics.296</th>\n",
              "      <th>characteristics.297</th>\n",
              "      <th>characteristics.298</th>\n",
              "      <th>characteristics.299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.051914</td>\n",
              "      <td>-0.040258</td>\n",
              "      <td>0.025391</td>\n",
              "      <td>0.048084</td>\n",
              "      <td>0.011030</td>\n",
              "      <td>-0.028035</td>\n",
              "      <td>-0.020593</td>\n",
              "      <td>-0.007132</td>\n",
              "      <td>0.027099</td>\n",
              "      <td>-0.028960</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.078753</td>\n",
              "      <td>-0.106597</td>\n",
              "      <td>0.048499</td>\n",
              "      <td>0.030822</td>\n",
              "      <td>-0.017637</td>\n",
              "      <td>0.039964</td>\n",
              "      <td>-0.015342</td>\n",
              "      <td>-0.041639</td>\n",
              "      <td>-0.041431</td>\n",
              "      <td>-0.079370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.072009</td>\n",
              "      <td>0.059222</td>\n",
              "      <td>0.020265</td>\n",
              "      <td>-0.006977</td>\n",
              "      <td>-0.083824</td>\n",
              "      <td>0.064424</td>\n",
              "      <td>-0.004561</td>\n",
              "      <td>-0.011842</td>\n",
              "      <td>-0.014513</td>\n",
              "      <td>0.026763</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003411</td>\n",
              "      <td>-0.099625</td>\n",
              "      <td>0.045395</td>\n",
              "      <td>-0.020554</td>\n",
              "      <td>-0.018369</td>\n",
              "      <td>-0.017763</td>\n",
              "      <td>0.008698</td>\n",
              "      <td>0.044429</td>\n",
              "      <td>0.017260</td>\n",
              "      <td>-0.026230</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.001555</td>\n",
              "      <td>0.030092</td>\n",
              "      <td>-0.002284</td>\n",
              "      <td>-0.011540</td>\n",
              "      <td>0.035198</td>\n",
              "      <td>0.011356</td>\n",
              "      <td>-0.013616</td>\n",
              "      <td>0.011064</td>\n",
              "      <td>-0.019440</td>\n",
              "      <td>-0.035191</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001901</td>\n",
              "      <td>-0.043206</td>\n",
              "      <td>-0.053606</td>\n",
              "      <td>-0.018003</td>\n",
              "      <td>-0.010898</td>\n",
              "      <td>0.009663</td>\n",
              "      <td>-0.004444</td>\n",
              "      <td>0.099461</td>\n",
              "      <td>0.008132</td>\n",
              "      <td>-0.051409</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 1200 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    title.0   title.1   title.2   title.3   title.4   title.5   title.6  \\\n",
              "0  0.051914 -0.040258  0.025391  0.048084  0.011030 -0.028035 -0.020593   \n",
              "1  0.072009  0.059222  0.020265 -0.006977 -0.083824  0.064424 -0.004561   \n",
              "2  0.001555  0.030092 -0.002284 -0.011540  0.035198  0.011356 -0.013616   \n",
              "\n",
              "    title.7   title.8   title.9  ...  characteristics.290  \\\n",
              "0 -0.007132  0.027099 -0.028960  ...            -0.078753   \n",
              "1 -0.011842 -0.014513  0.026763  ...             0.003411   \n",
              "2  0.011064 -0.019440 -0.035191  ...             0.001901   \n",
              "\n",
              "   characteristics.291  characteristics.292  characteristics.293  \\\n",
              "0            -0.106597             0.048499             0.030822   \n",
              "1            -0.099625             0.045395            -0.020554   \n",
              "2            -0.043206            -0.053606            -0.018003   \n",
              "\n",
              "   characteristics.294  characteristics.295  characteristics.296  \\\n",
              "0            -0.017637             0.039964            -0.015342   \n",
              "1            -0.018369            -0.017763             0.008698   \n",
              "2            -0.010898             0.009663            -0.004444   \n",
              "\n",
              "   characteristics.297  characteristics.298  characteristics.299  \n",
              "0            -0.041639            -0.041431            -0.079370  \n",
              "1             0.044429             0.017260            -0.026230  \n",
              "2             0.099461             0.008132            -0.051409  \n",
              "\n",
              "[3 rows x 1200 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_folder = 'embeddings'\n",
        "\n",
        "df_embeddings = data_processor.embedder.generate_embeddings(train_data, text_features, embeddings_folder, postfix='train')\n",
        "df_embeddings.iloc[0:3]"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train-valid-test split"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Firstly, accumulate all the data in one dataframe. Then split it taking only features used while training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets = ['category_id', 'category_name']\n",
        "target = targets[0]\n",
        "\n",
        "text_features = ['title', 'description', 'attributes', 'characteristics']\n",
        "embedded_features = df_embeddings.columns.to_list()\n",
        "unused_features = ['product_id']\n",
        "\n",
        "training_features = embedded_features + [f for f in train_data.columns.to_list() if f not in targets + text_features + unused_features]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "def data_split(df: pd.DataFrame, training_features: list[str], target: str, data_frac: float, train_frac: float, valid_frac: float, test_frac: float) -> pd.DataFrame:\n",
        "    assert train_frac + valid_frac + test_frac == 1\n",
        "    # make stratified subsets\n",
        "    df_result = df.groupby(target, group_keys=False).apply(lambda x: x.sample(frac=data_frac, random_state=SEED))\n",
        "    df_result = df_result[training_features + targets]\n",
        "\n",
        "    # split the df_result into train and test subsets\n",
        "    df_train = df_result.groupby(target, group_keys=False).apply(lambda x: x.sample(frac=train_frac, random_state=SEED))\n",
        "    df_valid_test = df_result[~df_result.isin(df_train)].dropna(how='all')\n",
        "    df_valid = df_valid_test.groupby(target, group_keys=False).apply(lambda x: x.sample(frac=valid_frac/(valid_frac+test_frac), random_state=SEED))\n",
        "    df_test = df_valid_test[~df_valid_test.isin(df_valid)].dropna(how='all')\n",
        "\n",
        "    class_balance = {\n",
        "        \"train\": df_train[target].value_counts(),\n",
        "        \"valid\": df_valid[target].value_counts(),\n",
        "        \"test\": df_test[target].value_counts(),\n",
        "    }\n",
        "    df_class_balance = pd.DataFrame(class_balance).sort_values(by='train', ascending=False)\n",
        "    df_class_balance.index.name = 'category_id'\n",
        "\n",
        "    return (\n",
        "        df_train[training_features],\n",
        "        df_train[target],\n",
        "        df_valid[training_features],\n",
        "        df_valid[target],\n",
        "        df_test[training_features],\n",
        "        df_test[target],\n",
        "        df_class_balance\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(78441, 1200)\n",
            "(16818, 1200)\n",
            "(16822, 1200)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>train</th>\n",
              "      <th>valid</th>\n",
              "      <th>test</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>category_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11937.0</th>\n",
              "      <td>4613</td>\n",
              "      <td>988</td>\n",
              "      <td>989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14922.0</th>\n",
              "      <td>2596</td>\n",
              "      <td>556</td>\n",
              "      <td>557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13651.0</th>\n",
              "      <td>1024</td>\n",
              "      <td>220</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13143.0</th>\n",
              "      <td>1022</td>\n",
              "      <td>219</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12980.0</th>\n",
              "      <td>855</td>\n",
              "      <td>184</td>\n",
              "      <td>183</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13632.0</th>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2751.0</th>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12554.0</th>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12428.0</th>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2844.0</th>\n",
              "      <td>35</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>874 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             train  valid  test\n",
              "category_id                    \n",
              "11937.0       4613    988   989\n",
              "14922.0       2596    556   557\n",
              "13651.0       1024    220   219\n",
              "13143.0       1022    219   219\n",
              "12980.0        855    184   183\n",
              "...            ...    ...   ...\n",
              "13632.0         35      8     7\n",
              "2751.0          35      8     7\n",
              "12554.0         35      8     7\n",
              "12428.0         35      8     7\n",
              "2844.0          35      8     7\n",
              "\n",
              "[874 rows x 3 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.concat([train_data, df_embeddings], axis=1)\n",
        "\n",
        "X_train, y_train, X_valid, y_valid, X_test, y_test, df_class_balance =\\\n",
        "    data_split(df, training_features, target, data_frac = 1, train_frac = 0.7, valid_frac = 0.15, test_frac = 0.15)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "df_class_balance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "wwsdbs40syld"
      },
      "source": [
        "# NN"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_samples = len(train_data)\n",
        "num_features = len(training_features)\n",
        "num_classes = len(df_class_balance)\n",
        "\n",
        "class_map = pd.Series(data=range(num_classes), index=df_class_balance.index).to_dict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "class KEDataset(Dataset):\n",
        "    def __init__(self, X: pd.DataFrame, y: pd.Series, is_labeled: bool = True):\n",
        "        self.X = X.to_numpy(dtype=float)\n",
        "        self.y = y.to_numpy(dtype=int)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], class_map[self.y[idx]]\n",
        "    \n",
        "\n",
        "def get_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test, batch_size: int):\n",
        "    train_loader = torch.utils.data.DataLoader(KEDataset(X_train, y_train), batch_size=batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(KEDataset(X_valid, y_valid), batch_size = batch_size, shuffle=True)\n",
        "    test_loader = torch.utils.data.DataLoader(KEDataset(X_test, y_test), batch_size = batch_size)\n",
        "    return train_loader, valid_loader, test_loader"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## NN Architecture"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I'm introducing the `FC_layer` class used as a building block of MLP.\n",
        "\n",
        "It's extremely useful to parametrize the number of layers in MLP for hyperparameter search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "r3bCKpZEsyld"
      },
      "outputs": [],
      "source": [
        "class FC_layer(NamedTuple):\n",
        "    num_neurons: int\n",
        "    activation: str\n",
        "    dropout_proba: float\n",
        "\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self,\n",
        "                 n_input: int,\n",
        "                 n_output: int,\n",
        "                 hidden_layers: Tuple[FC_layer]):\n",
        "        super().__init__()\n",
        "\n",
        "        layers = []\n",
        "        for hidden_layer in hidden_layers:\n",
        "            # the layer itself\n",
        "            layer = nn.Linear(n_input, hidden_layer.num_neurons)\n",
        "            layers.append(layer)\n",
        "            # batch normalization\n",
        "            bn = nn.BatchNorm1d(hidden_layer.num_neurons)\n",
        "            layers.append(bn)\n",
        "            # activation function\n",
        "            activation = getattr(nn, hidden_layer.activation)()\n",
        "            layers.append(activation)\n",
        "            # dropout layer\n",
        "            dropout = nn.Dropout(hidden_layer.dropout_proba)\n",
        "            layers.append(dropout)\n",
        "\n",
        "            n_input = hidden_layer.num_neurons  # the last layer n_input == the last hidden layer n_output\n",
        "\n",
        "        output_layer = nn.Linear(n_input, n_output)\n",
        "        layers.append(output_layer)\n",
        "\n",
        "        self.extractor = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        input = torch.flatten(x, start_dim=1)\n",
        "        out = self.extractor(input)\n",
        "        return out"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def train(model, dataloader, optimizer, criterion, epoch, verbose: bool = True):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_preds = []\n",
        "    y_targets = []\n",
        "\n",
        "    for X_batch, y_batch in dataloader:\n",
        "        X_batch = X_batch.to(DEVICE)\n",
        "        y_batch = y_batch.to(DEVICE)\n",
        "\n",
        "        y_pred = model(X_batch)\n",
        "\n",
        "        loss = criterion(y_pred, y_batch)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        y_preds += y_pred.argmax(-1).tolist()\n",
        "        y_targets += y_batch.tolist()\n",
        "        \n",
        "    weighted_f1 = f1_score(y_targets, y_preds, average='weighted')\n",
        "\n",
        "    if verbose and (epoch % LOG_INTERVAL == 0 or epoch == 1):\n",
        "        print(f'EPOCH: {epoch}')\n",
        "        print(f'Training loss: {loss.item():.4f}')\n",
        "        print(f'Training Weighted F1: {weighted_f1:.4f}')\n",
        "\n",
        "    return weighted_f1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test(model, dataloader, epoch, verbose: bool = True):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        y_preds = []\n",
        "        y_targets = []\n",
        "        \n",
        "        for X_batch, y_batch in dataloader:\n",
        "            X_batch = X_batch.to(DEVICE)\n",
        "            y_batch = y_batch.to(DEVICE)\n",
        "            y_pred = model(X_batch)\n",
        "            loss = F.cross_entropy(y_pred, y_batch)\n",
        "\n",
        "            y_preds += y_pred.argmax(-1).tolist()\n",
        "            y_targets += y_batch.tolist()\n",
        "\n",
        "    weighted_f1 = f1_score(y_targets, y_preds, average='weighted')\n",
        "\n",
        "    if verbose and (epoch % LOG_INTERVAL == 0 or epoch == 1):\n",
        "        print(f'Validation loss: {loss.item():.4f}')\n",
        "        print(f'Validation Weighted F1: {weighted_f1:.4f}')\n",
        "        print(\"_\" * 60)\n",
        "\n",
        "    return weighted_f1"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (extractor): Sequential(\n",
            "    (0): Linear(in_features=2074, out_features=2200, bias=True)\n",
            "    (1): BatchNorm1d(2200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01)\n",
            "    (3): Dropout(p=0, inplace=False)\n",
            "    (4): Linear(in_features=2200, out_features=1200, bias=True)\n",
            "    (5): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (6): ReLU()\n",
            "    (7): Dropout(p=0, inplace=False)\n",
            "    (8): Linear(in_features=1200, out_features=874, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "hidden_layers = (\n",
        "    FC_layer(2200, \"LeakyReLU\", 0),\n",
        "    FC_layer(1200, \"ReLU\", 0),\n",
        "    )\n",
        "\n",
        "model = NN(\n",
        "    n_input=num_features,\n",
        "    n_output=num_classes,\n",
        "    hidden_layers=hidden_layers\n",
        ").to(DEVICE)\n",
        "\n",
        "model.double()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optimizer = torch.optim.AdamW(model.parameters())\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "NUM_EPOCHS = 20\n",
        "BATCH_SIZE = 256\n",
        "train_loader, valid_loader, test_loader = get_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test, BATCH_SIZE)\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, criterion, epoch)\n",
        "    scheduler.step()\n",
        "    test(model, valid_loader, epoch)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluation on the Test Set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.1730\n",
            "Validation Weighted F1: 0.8623\n"
          ]
        }
      ],
      "source": [
        "_ = test(model, test_loader, LOG_INTERVAL)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Hyperparameters Search"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have ran 100 Optuna trials to find the best values for the following hyperparameters:\n",
        "\n",
        "- number of hidden layers\n",
        "- number of neurons in each hidden layer\n",
        "- activation function of each hidden layer\n",
        "- dropout probability after each hidden layer\n",
        "- learning rate and weight decay for `AdamW` optimizer\n",
        "- step size and gamma for `StepLR` scheduler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "def define_model(trial):\n",
        "    n_layers = trial.suggest_int(\"num_layers\", 0, 5)\n",
        "    layers = []\n",
        "\n",
        "    for i in range(n_layers):\n",
        "        out_features = trial.suggest_int(f\"num_neurons_l{i}\", 500, 3000)\n",
        "        activation_name = trial.suggest_categorical(f\"activation_l{i}\", [\"ReLU\", \"LeakyReLU\", \"ELU\"])\n",
        "        dropout_proba = trial.suggest_uniform(f\"dropout_l{i}\", 0, 0.3)\n",
        "\n",
        "        layer = FC_layer(out_features, activation_name, dropout_proba)\n",
        "        layers.append(layer)\n",
        "\n",
        "    return NN(n_input=num_features, n_output=num_classes, hidden_layers=tuple(layers))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I chose the validation set F1-Weighted score as the objective for maximization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "def objective(trial):\n",
        "    # generate the model\n",
        "    model = define_model(trial).to(DEVICE)\n",
        "    model.double()\n",
        "    # optimizer parameters\n",
        "    lr = trial.suggest_loguniform(\"lr\", 1e-5, 1e-1)\n",
        "    weight_decay = trial.suggest_uniform(\"weight_decay\", 0, 1e-3)\n",
        "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "    # scheduler parameters\n",
        "    step_size = trial.suggest_int(\"step_size\", 1, 14)\n",
        "    gamma = trial.suggest_uniform(\"gamma\", 0.1, 0.95)\n",
        "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n",
        "\n",
        "    with open(f\"./optuna/trial_{trial.number}.log\", \"w\") as log_file:\n",
        "        pprint(trial.params.items(), log_file)\n",
        "        pprint(model, log_file)\n",
        "        \n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        train_f1w = train(model, train_loader, optimizer, criterion, epoch, verbose=False)\n",
        "        scheduler.step()\n",
        "        val_f1w = test(model, valid_loader, epoch, verbose=False)\n",
        "        \n",
        "    return val_f1w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_study_stats(study):\n",
        "    pruned_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.PRUNED]\n",
        "    complete_trials = [t for t in study.trials if t.state == optuna.structs.TrialState.COMPLETE]\n",
        "\n",
        "    print(\"Study statistics: \")\n",
        "    print(\"  Number of finished trials: \", len(study.trials))\n",
        "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
        "    print(\"  Number of complete trials: \", len(complete_trials))\n",
        "\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: \", trial.value)\n",
        "\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "        print(\"    {}: {}\".format(key, value))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "\n",
        "NUM_EPOCHS = 15\n",
        "BATCH_SIZE = 1024\n",
        "train_loader, valid_loader, test_loader = get_data_loaders(X_train, y_train, X_valid, y_valid, X_test, y_test, BATCH_SIZE)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "sampler = TPESampler(seed=SEED)\n",
        "pruner = optuna.pruners.MedianPruner()\n",
        "study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=pruner)\n",
        "\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "print_study_stats(study)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Best Model Training"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the hyperparameters search, the best model has shown `0.8959` F1-Weighted score on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation loss: 0.5056\n",
            "Validation Weighted F1: 0.8959\n"
          ]
        }
      ],
      "source": [
        "_ = test(model, test_loader, LOG_INTERVAL)\n",
        "torch.save(model, './models/model_best_train.pt')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The best model has the following architecture:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NN(\n",
            "  (extractor): Sequential(\n",
            "    (0): Linear(in_features=1200, out_features=2432, bias=True)\n",
            "    (1): BatchNorm1d(2432, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ELU(alpha=1.0)\n",
            "    (3): Dropout(p=0.13118521108680903, inplace=False)\n",
            "    (4): Linear(in_features=2432, out_features=874, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "hidden_layers = (\n",
        "    FC_layer(2432, \"ELU\", 0.13118521108680903),\n",
        "    )\n",
        "\n",
        "model = NN(\n",
        "    n_input=num_features,\n",
        "    n_output=num_classes,\n",
        "    hidden_layers=hidden_layers\n",
        ").to(DEVICE)\n",
        "\n",
        "model.double()\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final model will have the whole dataset for training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "112128"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "BATCH_SIZE = 256\n",
        "\n",
        "dataset = df[training_features + targets]\n",
        "train_loader = torch.utils.data.DataLoader(KEDataset(dataset[training_features], dataset[target]), batch_size=BATCH_SIZE, shuffle=False)\n",
        "len(train_loader) * BATCH_SIZE"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Run the training loop:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "EPOCH: 1\n",
            "Training loss: 3.3702\n",
            "Training Weighted F1: 0.5070\n",
            "EPOCH: 11\n",
            "Training loss: 1.2742\n",
            "Training Weighted F1: 0.9248\n",
            "EPOCH: 22\n",
            "Training loss: 0.6895\n",
            "Training Weighted F1: 0.9729\n",
            "EPOCH: 33\n",
            "Training loss: 0.6635\n",
            "Training Weighted F1: 0.9813\n"
          ]
        }
      ],
      "source": [
        "NUM_EPOCHS = 33\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=6.490126177038149e-05, weight_decay=0.00015206958986612742)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.65)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, criterion, epoch)\n",
        "    scheduler.step()\n",
        "\n",
        "torch.save(model, './models/model_submission.pt')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predictions for Submission"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Test Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [],
      "source": [
        "# unwrapping the text data jsons\n",
        "test_data['title'], test_data['description'], test_data['attributes'], test_data['characteristics'] =\\\n",
        "    zip(*test_data['text_fields'].apply(data_processor.process_json))\n",
        "\n",
        "# text features processing\n",
        "test_data_path = './test_data_preprocessed_final.csv'\n",
        "test_data = get_df_with_processed_text_features\\\n",
        "    (test_data, text_features, data_processor.text_processor, test_data_path)\n",
        "\n",
        "# generate embeddings for textual data\n",
        "df_test_embeddings = data_processor.embedder.generate_embeddings(test_data, text_features, embeddings_folder, postfix='test')\n",
        "\n",
        "# construct a dataset\n",
        "BATCH_SIZE = 1024\n",
        "df_submit = pd.concat([test_data, df_test_embeddings], axis=1)[training_features]\n",
        "dl_submit = torch.utils.data.DataLoader(KEDataset(df_submit, pd.Series([2601] * len(df_submit))), batch_size=BATCH_SIZE, shuffle=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving the Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_preds = []\n",
        "    for X_batch, _ in dl_submit:\n",
        "        X_batch = X_batch.to(DEVICE)\n",
        "        y_pred = model(X_batch)\n",
        "        y_preds += y_pred.argmax(-1).tolist()\n",
        "\n",
        "inv_class_map = {v: k for k, v in class_map.items()}\n",
        "y_preds = pd.Series(y_preds).apply(lambda x: int(inv_class_map[x]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>product_id</th>\n",
              "      <th>predicted_category_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1997646</td>\n",
              "      <td>13495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>927375</td>\n",
              "      <td>14922</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1921513</td>\n",
              "      <td>2803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1668662</td>\n",
              "      <td>12524</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1467778</td>\n",
              "      <td>13887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16855</th>\n",
              "      <td>1914264</td>\n",
              "      <td>11645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16856</th>\n",
              "      <td>1310569</td>\n",
              "      <td>12357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16857</th>\n",
              "      <td>978095</td>\n",
              "      <td>13651</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16858</th>\n",
              "      <td>797547</td>\n",
              "      <td>2740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16859</th>\n",
              "      <td>703835</td>\n",
              "      <td>11757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>16860 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       product_id  predicted_category_id\n",
              "0         1997646                  13495\n",
              "1          927375                  14922\n",
              "2         1921513                   2803\n",
              "3         1668662                  12524\n",
              "4         1467778                  13887\n",
              "...           ...                    ...\n",
              "16855     1914264                  11645\n",
              "16856     1310569                  12357\n",
              "16857      978095                  13651\n",
              "16858      797547                   2740\n",
              "16859      703835                  11757\n",
              "\n",
              "[16860 rows x 2 columns]"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result = pd.DataFrame({\n",
        "    'product_id': test_data.index.to_series().reset_index(drop=True),\n",
        "    'predicted_category_id': y_preds\n",
        "    })\n",
        "result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "result.to_parquet('result.parquet')"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prediction Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_categories = result.set_index('product_id')['predicted_category_id'].apply(lambda x: category_name[x])\n",
        "titles_preds = pd.concat([test_data['title'], pred_categories], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Title: светодиодный лента smart led strip light пульт метр usb bluetooth\n",
            "Prediction: Все категории->Товары для дома->Товары для праздников->Новогодние товары->Гирлянды\n",
            "\n",
            "Title: стекло пленка керамика матовый honor lite pro 30s psmart p40 lite\n",
            "Prediction: Все категории->Электроника->Смартфоны и телефоны->Аксессуары и запчасти->Защитные стекла и пленки->Защитные стекла\n",
            "\n",
            "Title: проводной наушник микрофон jack ios android\n",
            "Prediction: Все категории->Электроника->Наушники и аудиотехника->Наушники->Проводные наушники\n",
            "\n",
            "Title: декоративный табличка правило кухня подставка горячее разделочный доска\n",
            "Prediction: Все категории->Товары для дома->Товары для кухни->Кухонные аксессуары->Скатерти и подставки под горячее\n",
            "\n",
            "Title: подставка ложка керамический подложка клубника лаванда лимон\n",
            "Prediction: Все категории->Товары для дома->Товары для кухни->Порядок на кухне->Подставки для столовых приборов\n",
            "\n",
            "Title: футболка женский принт премиальный хлопок\n",
            "Prediction: Все категории->Одежда->Женская одежда->Футболки и топы->Футболки\n",
            "\n",
            "Title: топ чебоксарский трикотаж\n",
            "Prediction: Все категории->Одежда->Женская одежда->Футболки и топы->Топы\n",
            "\n",
            "Title: зарядный устройство адаптер питание usb\n",
            "Prediction: Все категории->Электроника->Смартфоны и телефоны->Аксессуары и запчасти->Зарядные устройства и кабели->Сетевые зарядные устройства\n",
            "\n",
            "Title: трусы женский\n",
            "Prediction: Все категории->Одежда->Женская одежда->Белье и купальники->Трусы\n",
            "\n",
            "Title: чехол силиконовый xiaomi\n",
            "Prediction: Все категории->Электроника->Смартфоны и телефоны->Аксессуары и запчасти->Чехлы\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in range(10):\n",
        "    print(\"Title:\", titles_preds.iloc[i]['title'])\n",
        "    print(\"Prediction:\", titles_preds.iloc[i]['predicted_category_id'])\n",
        "    print()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "ke_test_cb_hf",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
